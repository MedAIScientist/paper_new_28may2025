# PDF Web Scraper with RAG-Ready PDF Conversion

This project allows you to extract links from a PDF file, scrape their content, and convert the scraped data into clean PDF files with copyable text for RAG implementation.

## Features

- âœ… Extraction of links from a PDF file
- âœ… Saving links to a CSV file
- âœ… Scraping corresponding web pages with Playwright
- âœ… Extraction of relevant content (text, paragraphs)
- âœ… Saving results to a JSON file
- âœ… **Converting scraped content to clean PDF files with copyable text for RAG systems**

## Prerequisites

- Python 3.8+
- Dependencies listed in `requirements.txt`

## Installation

1. Clone this repository or download the files
2. Install dependencies:

```bash
pip install -r requirements.txt
```

3. Install browsers for Playwright:

```bash
playwright install
```

## Usage

### Complete Workflow (New PDF â†’ Scraped PDFs)

1. **Extract links from a PDF and scrape content:**
```bash
python main.py your_document(deep_research).pdf
```

2. **Convert scraped data to clean PDFs:**
```bash
python batch_convert_to_pdf.py
```

### Quick Conversion (Existing JSON â†’ PDFs)

If you already have a `results.json` file from previous scraping:

```bash
python batch_convert_to_pdf.py
```

## Output

- **`links.csv`**: Extracted links from the source PDF
- **`results.json`**: Scraped content in JSON format
- **`converted_pdfs/`**: Clean PDF files ready for RAG implementation

## PDF Format

The generated PDFs contain:
- âœ… **Clean, relevant content only** (no abstract metadata)
- âœ… **Copyable text** for RAG processing
- âœ… **Structured format** with title, source, and main content
- âœ… **Optimized file sizes** for efficient processing

## File Structure

```
pdf_scraper/
â”œâ”€â”€ main.py                    # Main scraping script
â”œâ”€â”€ batch_convert_to_pdf.py    # PDF conversion script
â”œâ”€â”€ json_to_pdf_converter.py   # PDF converter class
â”œâ”€â”€ requirements.txt           # Dependencies
â”œâ”€â”€ results.json              # Scraped data (generated)
â”œâ”€â”€ links.csv                 # Extracted links (generated)
â””â”€â”€ converted_pdfs/           # Generated PDFs (created)
```

## Example Usage

```bash
# Complete workflow
python main.py              # Extract and scrape
python batch_convert_to_pdf.py  # Convert to PDFs

# Your PDFs are now ready in converted_pdfs/ for RAG implementation!
```

## Notes

- The PDF converter automatically filters out irrelevant content like abstracts, metadata, and navigation elements
- Generated PDFs are optimized for RAG systems with clean, searchable text
- File names are automatically generated based on source domain and article title

## Data Structure

### CSV Format

The CSV file containing the extracted links has the following structure:

```
url,page,type
https://example.com,1,hyperlink
https://another-example.com,2,text
```

### JSON Format

The JSON file containing the scraping results has the following structure:

```json
[
  {
    "url": "https://example.com",
    "title": "Page title",
    "domain": "example.com",
    "date_scraped": "2023-10-20T15:30:45.123456",
    "content": {
      "full_text": "Full text of the page...",
      "paragraphs": [
        "First significant paragraph...",
        "Second significant paragraph..."
      ]
    }
  }
]
```

### ðŸ†• Generated PDF Format

The generated PDF files are optimized for RAG systems with:

- **Copyable text**: All text can be selected and copied
- **Structured layout**: Title, abstract, and body sections
- **Clean formatting**: Proper spacing and typography
- **Metadata**: Source URL, domain, and scraping date
- **Meaningful filenames**: Format: `001_domain_article_title.pdf`

## RAG Integration

The generated PDF files are ready for use in RAG (Retrieval-Augmented Generation) systems. Each PDF contains:

1. **Title**: Clean article title
2. **Metadata**: Source URL, domain, scraping date
3. **Full Text**: Complete article content in readable paragraphs


### File Naming Convention

```
001_pubmed_ncbi_nlm_nih_gov_Exploring_the_Role_of_Psychologists.pdf
002_pubmed_ncbi_nlm_nih_gov_Proactive_clinical_review_of_patients.pdf
003_pubmed_ncbi_nlm_nih_gov_Mobile_Gaming_for_Cognitive_Health.pdf
```

Format: `{index:03d}_{domain}_{title}.pdf`

## Example Workflow

```bash
# 1. Extract links from your PDF
python main.py research_paper.pdf --max-urls 20

# 2. Convert to RAG-ready PDFs
python batch_convert_to_pdf.py

# 3. Your PDF files are now ready in the 'converted_pdfs' directory
ls converted_pdfs/
```

## Limitations

- The scraper is configured to respect robots.txt rules
- Scraping can take time depending on the number of links and page complexity
- Some sites may block scraping robots
- PDF conversion requires sufficient memory for large articles

## Dependencies

- `playwright`: Web scraping
- `pymupdf`: PDF text extraction
- `pandas`: Data manipulation
- `beautifulsoup4`: HTML parsing
- `reportlab`: PDF generation
- `requests`: HTTP requests
